{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPiTw5hTTws5jt8dK6qGwmg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yaswanthyarra/GAN-for-microexpression-augmentation/blob/main/CNN_GA_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H2yP2AguY3S9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCmtZiBpY-A3",
        "outputId": "8d0605e6-3d8d-4370-a611-e47dbd4fe70c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/My Drive/CASMEII/Final_Apex_Frames_Segregated'\n",
        "augmented_dir='/content/drive/My Drive/CASMEII/Augmented_Apex_Frames'"
      ],
      "metadata": {
        "id": "27nIYJGuZQZT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "dataset_dir = '/content/drive/My Drive/CASMEII/Final_Apex_Frames_Segregated'\n",
        "\n",
        "label_dict = {'happiness': 0, 'disgust': 1, 'repression': 2, 'surprise': 3, 'fear': 4, 'others': 6, 'sadness': 5}\n",
        "\n",
        "expression_images = []\n",
        "expression_labels = []\n",
        "# Initialize dictionaries to count instances for each label\n",
        "label_counts = {}\n",
        "for label in set([0,1,2,3,4,5,6]):\n",
        "    label_counts[label] = 0\n",
        "\n",
        "for class_name, label in label_dict.items():\n",
        "    class_dir = os.path.join(dataset_dir, class_name)\n",
        "    images = os.listdir(class_dir)\n",
        "\n",
        "    for image_file in images:\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = cv2.imread(image_path)  # Load the image using OpenCV\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        image = cv2.resize(image, (64,64))\n",
        "        # Apply histogram equalization\n",
        "        image = cv2.equalizeHist(image)\n",
        "        if label==1:\n",
        "          expression_images.append(image)\n",
        "          expression_labels.append(label)\n",
        "          # Update the label count\n",
        "          label_counts[label] += 1\n",
        "        if label==6:\n",
        "          expression_images.append(image)\n",
        "          expression_labels.append(label)\n",
        "          # Update the label count\n",
        "          label_counts[label] += 1\n",
        "\n",
        "\n",
        "\n",
        "        expression_images.append(image)\n",
        "        expression_labels.append(label)\n",
        "        # Update the label count\n",
        "        label_counts[label] += 1\n",
        "# Print the label counts\n",
        "\n",
        "for label, count in label_counts.items():\n",
        "    label_name = [key for key, value in label_dict.items() if value == label][0]\n",
        "    print(f'Label {label_name}: {count} instances')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tg63ziwZVGO",
        "outputId": "df88a88c-ddd3-4c48-bb0b-bf74b7bdb458"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label happiness: 32 instances\n",
            "Label disgust: 126 instances\n",
            "Label repression: 27 instances\n",
            "Label surprise: 25 instances\n",
            "Label fear: 2 instances\n",
            "Label sadness: 7 instances\n",
            "Label others: 198 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_dir='/content/drive/My Drive/CASMEII/Augmented_Apex_Frames'\n",
        "label_dict = {'happiness': 0, 'repression': 2, 'surprise': 3, 'fear': 4, 'sadness': 5}\n",
        "# Initialize dictionaries to count instances for each label\n",
        "label_counts = {}\n",
        "for label in set([0,2,3,4,5]):\n",
        "    label_counts[label] = 0\n",
        "\n",
        "for class_name, label in label_dict.items():\n",
        "    class_dir = os.path.join(augmented_dir, class_name)\n",
        "    images = os.listdir(class_dir)\n",
        "\n",
        "    for image_file in images:\n",
        "        image_path = os.path.join(class_dir, image_file)\n",
        "        image = cv2.imread(image_path)  # Load the image using OpenCV\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        # Apply histogram equalization\n",
        "        image = cv2.equalizeHist(image)\n",
        "        if label==0:\n",
        "          expression_images.append(image)\n",
        "          expression_labels.append(label)\n",
        "          label_counts[label] += 1\n",
        "\n",
        "        expression_images.append(image)\n",
        "        expression_labels.append(label)\n",
        "        label_counts[label] += 1\n",
        "for label, count in label_counts.items():\n",
        "    label_name = [key for key, value in label_dict.items() if value == label][0]\n",
        "    print(f'Label {label_name}: {count} instances')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfTUJTf7ZY0K",
        "outputId": "ad666267-1d94-489e-b732-67edc24fd46c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label happiness: 128 instances\n",
            "Label repression: 64 instances\n",
            "Label surprise: 50 instances\n",
            "Label fear: 60 instances\n",
            "Label sadness: 63 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert lists to NumPy arrays\n",
        "expression_images = np.array(expression_images)\n",
        "expression_labels = np.array(expression_labels)\n",
        "\n",
        "# Check the shape of the image data and labels\n",
        "print(\"Expression Images Shape:\", expression_images.shape)\n",
        "print(\"Expression Labels Shape:\", expression_labels.shape)\n",
        "# Obtain the number of class labels\n",
        "num_classes = len(np.unique(expression_labels))\n",
        "\n",
        "# Stratified Splitting of data into training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(expression_images, expression_labels, test_size=0.2, stratify=expression_labels, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS6d8Mn_Ze2y",
        "outputId": "c23c082c-ee88-4c9b-abf9-a0466016fba6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expression Images Shape: (1147, 64, 64)\n",
            "Expression Labels Shape: (1147,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 1)),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Conv2D(128, (3,3), activation='relu'),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.29),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Define the optimizer with a specific learning rate\n",
        "optimizer = Adam(learning_rate=0.0006)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "aV11gHQaZf6j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=52, batch_size=17, validation_data=(test_images, test_labels))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1MRNevkZgHi",
        "outputId": "75e88e08-652a-413d-dd48-ed0f584956e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/52\n",
            "54/54 [==============================] - 10s 151ms/step - loss: 5.0617 - accuracy: 0.3413 - val_loss: 0.9890 - val_accuracy: 0.7870\n",
            "Epoch 2/52\n",
            "54/54 [==============================] - 6s 111ms/step - loss: 0.8225 - accuracy: 0.7110 - val_loss: 0.5050 - val_accuracy: 0.8696\n",
            "Epoch 3/52\n",
            "54/54 [==============================] - 8s 146ms/step - loss: 0.5707 - accuracy: 0.7928 - val_loss: 0.4549 - val_accuracy: 0.8435\n",
            "Epoch 4/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.4803 - accuracy: 0.8212 - val_loss: 0.4111 - val_accuracy: 0.8609\n",
            "Epoch 5/52\n",
            "54/54 [==============================] - 8s 144ms/step - loss: 0.4213 - accuracy: 0.8462 - val_loss: 0.3580 - val_accuracy: 0.8783\n",
            "Epoch 6/52\n",
            "54/54 [==============================] - 6s 109ms/step - loss: 0.3678 - accuracy: 0.8571 - val_loss: 0.4284 - val_accuracy: 0.8652\n",
            "Epoch 7/52\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.3297 - accuracy: 0.8757 - val_loss: 0.3570 - val_accuracy: 0.8696\n",
            "Epoch 8/52\n",
            "54/54 [==============================] - 9s 162ms/step - loss: 0.3119 - accuracy: 0.8899 - val_loss: 0.3661 - val_accuracy: 0.8826\n",
            "Epoch 9/52\n",
            "54/54 [==============================] - 6s 111ms/step - loss: 0.2696 - accuracy: 0.9051 - val_loss: 0.3458 - val_accuracy: 0.8913\n",
            "Epoch 10/52\n",
            "54/54 [==============================] - 8s 146ms/step - loss: 0.2858 - accuracy: 0.8975 - val_loss: 0.3352 - val_accuracy: 0.9130\n",
            "Epoch 11/52\n",
            "54/54 [==============================] - 6s 106ms/step - loss: 0.2610 - accuracy: 0.9073 - val_loss: 0.3651 - val_accuracy: 0.8783\n",
            "Epoch 12/52\n",
            "54/54 [==============================] - 8s 146ms/step - loss: 0.2270 - accuracy: 0.9117 - val_loss: 0.3832 - val_accuracy: 0.8913\n",
            "Epoch 13/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.1783 - accuracy: 0.9357 - val_loss: 0.2775 - val_accuracy: 0.9217\n",
            "Epoch 14/52\n",
            "54/54 [==============================] - 8s 144ms/step - loss: 0.2024 - accuracy: 0.9237 - val_loss: 0.3774 - val_accuracy: 0.8913\n",
            "Epoch 15/52\n",
            "54/54 [==============================] - 6s 107ms/step - loss: 0.1818 - accuracy: 0.9357 - val_loss: 0.3230 - val_accuracy: 0.9130\n",
            "Epoch 16/52\n",
            "54/54 [==============================] - 7s 139ms/step - loss: 0.1633 - accuracy: 0.9466 - val_loss: 0.3647 - val_accuracy: 0.8913\n",
            "Epoch 17/52\n",
            "54/54 [==============================] - 7s 120ms/step - loss: 0.1436 - accuracy: 0.9477 - val_loss: 0.3381 - val_accuracy: 0.9087\n",
            "Epoch 18/52\n",
            "54/54 [==============================] - 7s 136ms/step - loss: 0.1311 - accuracy: 0.9553 - val_loss: 0.3190 - val_accuracy: 0.9130\n",
            "Epoch 19/52\n",
            "54/54 [==============================] - 6s 117ms/step - loss: 0.1327 - accuracy: 0.9542 - val_loss: 0.3942 - val_accuracy: 0.9087\n",
            "Epoch 20/52\n",
            "54/54 [==============================] - 7s 127ms/step - loss: 0.1075 - accuracy: 0.9684 - val_loss: 0.3828 - val_accuracy: 0.9304\n",
            "Epoch 21/52\n",
            "54/54 [==============================] - 7s 127ms/step - loss: 0.1180 - accuracy: 0.9640 - val_loss: 0.3103 - val_accuracy: 0.9348\n",
            "Epoch 22/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.1235 - accuracy: 0.9542 - val_loss: 0.3538 - val_accuracy: 0.9304\n",
            "Epoch 23/52\n",
            "54/54 [==============================] - 8s 140ms/step - loss: 0.0795 - accuracy: 0.9727 - val_loss: 0.3471 - val_accuracy: 0.9348\n",
            "Epoch 24/52\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.0558 - accuracy: 0.9804 - val_loss: 0.3258 - val_accuracy: 0.9304\n",
            "Epoch 25/52\n",
            "54/54 [==============================] - 8s 146ms/step - loss: 0.0636 - accuracy: 0.9738 - val_loss: 0.3395 - val_accuracy: 0.9087\n",
            "Epoch 26/52\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.0399 - accuracy: 0.9847 - val_loss: 0.4018 - val_accuracy: 0.9043\n",
            "Epoch 27/52\n",
            "54/54 [==============================] - 8s 147ms/step - loss: 0.0970 - accuracy: 0.9651 - val_loss: 0.3732 - val_accuracy: 0.9087\n",
            "Epoch 28/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.0690 - accuracy: 0.9716 - val_loss: 0.4332 - val_accuracy: 0.9174\n",
            "Epoch 29/52\n",
            "54/54 [==============================] - 8s 145ms/step - loss: 0.0644 - accuracy: 0.9738 - val_loss: 0.5165 - val_accuracy: 0.8913\n",
            "Epoch 30/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.0894 - accuracy: 0.9695 - val_loss: 0.3522 - val_accuracy: 0.9174\n",
            "Epoch 31/52\n",
            "54/54 [==============================] - 8s 150ms/step - loss: 0.0495 - accuracy: 0.9815 - val_loss: 0.3437 - val_accuracy: 0.9174\n",
            "Epoch 32/52\n",
            "54/54 [==============================] - 6s 107ms/step - loss: 0.0699 - accuracy: 0.9782 - val_loss: 0.3096 - val_accuracy: 0.9217\n",
            "Epoch 33/52\n",
            "54/54 [==============================] - 8s 141ms/step - loss: 0.0882 - accuracy: 0.9749 - val_loss: 0.3010 - val_accuracy: 0.9261\n",
            "Epoch 34/52\n",
            "54/54 [==============================] - 6s 111ms/step - loss: 0.0756 - accuracy: 0.9738 - val_loss: 0.3830 - val_accuracy: 0.9130\n",
            "Epoch 35/52\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.0911 - accuracy: 0.9706 - val_loss: 0.3693 - val_accuracy: 0.9217\n",
            "Epoch 36/52\n",
            "54/54 [==============================] - 7s 121ms/step - loss: 0.0569 - accuracy: 0.9804 - val_loss: 0.3777 - val_accuracy: 0.9348\n",
            "Epoch 37/52\n",
            "54/54 [==============================] - 7s 125ms/step - loss: 0.0245 - accuracy: 0.9935 - val_loss: 0.5126 - val_accuracy: 0.9391\n",
            "Epoch 38/52\n",
            "54/54 [==============================] - 7s 133ms/step - loss: 0.0544 - accuracy: 0.9858 - val_loss: 0.4173 - val_accuracy: 0.9174\n",
            "Epoch 39/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.0491 - accuracy: 0.9836 - val_loss: 0.3030 - val_accuracy: 0.9435\n",
            "Epoch 40/52\n",
            "54/54 [==============================] - 8s 145ms/step - loss: 0.0362 - accuracy: 0.9858 - val_loss: 0.5421 - val_accuracy: 0.9391\n",
            "Epoch 41/52\n",
            "54/54 [==============================] - 9s 163ms/step - loss: 0.0282 - accuracy: 0.9945 - val_loss: 0.4533 - val_accuracy: 0.9304\n",
            "Epoch 42/52\n",
            "54/54 [==============================] - 7s 123ms/step - loss: 0.0247 - accuracy: 0.9913 - val_loss: 0.4844 - val_accuracy: 0.9261\n",
            "Epoch 43/52\n",
            "54/54 [==============================] - 6s 112ms/step - loss: 0.0273 - accuracy: 0.9924 - val_loss: 0.4479 - val_accuracy: 0.9304\n",
            "Epoch 44/52\n",
            "54/54 [==============================] - 7s 137ms/step - loss: 0.0330 - accuracy: 0.9880 - val_loss: 0.4289 - val_accuracy: 0.9304\n",
            "Epoch 45/52\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.0571 - accuracy: 0.9793 - val_loss: 0.4013 - val_accuracy: 0.9304\n",
            "Epoch 46/52\n",
            "54/54 [==============================] - 7s 137ms/step - loss: 0.0312 - accuracy: 0.9880 - val_loss: 0.5364 - val_accuracy: 0.9348\n",
            "Epoch 47/52\n",
            "54/54 [==============================] - 6s 114ms/step - loss: 0.0440 - accuracy: 0.9847 - val_loss: 0.6630 - val_accuracy: 0.9174\n",
            "Epoch 48/52\n",
            "54/54 [==============================] - 7s 132ms/step - loss: 0.0166 - accuracy: 0.9967 - val_loss: 0.5955 - val_accuracy: 0.9130\n",
            "Epoch 49/52\n",
            "54/54 [==============================] - 6s 113ms/step - loss: 0.0448 - accuracy: 0.9804 - val_loss: 0.4983 - val_accuracy: 0.9000\n",
            "Epoch 50/52\n",
            "54/54 [==============================] - 7s 136ms/step - loss: 0.0562 - accuracy: 0.9836 - val_loss: 0.4278 - val_accuracy: 0.9304\n",
            "Epoch 51/52\n",
            "54/54 [==============================] - 6s 108ms/step - loss: 0.0503 - accuracy: 0.9880 - val_loss: 0.5132 - val_accuracy: 0.9217\n",
            "Epoch 52/52\n",
            "54/54 [==============================] - 8s 144ms/step - loss: 0.0280 - accuracy: 0.9902 - val_loss: 0.5663 - val_accuracy: 0.9348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a4dcd2aa170>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEk-3KaXZqq9",
        "outputId": "ffe235a9-59ac-433e-d898-3da3638c794b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 - 1s - loss: 0.5663 - accuracy: 0.9348 - 773ms/epoch - 97ms/step\n",
            "Test accuracy: 0.9347826242446899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate precision, recall, F1-score, and support\n",
        "report = classification_report(test_labels, predicted_labels)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUYKhdCPZtjA",
        "outputId": "b4fc7186-518c-41e9-94ef-7a23375d55d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 1s 65ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.96        58\n",
            "           1       0.88      0.92      0.90        25\n",
            "           2       1.00      0.94      0.97        31\n",
            "           3       0.96      0.88      0.92        25\n",
            "           4       1.00      1.00      1.00        24\n",
            "           5       1.00      0.93      0.96        27\n",
            "           6       0.79      0.95      0.86        40\n",
            "\n",
            "    accuracy                           0.93       230\n",
            "   macro avg       0.94      0.93      0.94       230\n",
            "weighted avg       0.94      0.93      0.94       230\n",
            "\n"
          ]
        }
      ]
    }
  ]
}